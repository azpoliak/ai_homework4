# ai_homework4
Implementation of ML algorithms for AI Homework4

Adam Poliak, Sayge Schell
Dec 4th, 2015

To run, do the following:
python train_and_test.py -d=congress -p=75 -m=0 -test
-d refers to the data set
-p refers to the percent, if -d is monk, then instead of -p=(int), do 1, 2, or 3 to determine with monk data set
-m refers to machine learning method

**TODO**
-igr refers to information gain ratio in the case m is the decision tree
-pr refers to pruning in the case m is the decision tree

**Class Descriptions**
decision_tree.py - Contains structure for decision tree
naive_bayes.py - Contains structure for naive bayes
neural_network.py - Contains structure for neural network
train_and_test.py - Driver program to use structures

Please note, for precision, the value for the first data set was chosen as the 'positive' one. All other values were set
to be negatives.

*Decision Trees* -
Key: IGR = Information Gain ratio, IG = Information Gain, NP = No pruning, P = Pruning

Congress- 
            IGR-NP          IG - NP             IGR -P              IGR - NP
Accuracy:   0.935779815614  0.926605504587
Precision:  0.931818181818  0.911111111111
Recall:     0.911111111111  0.911111111111

Monk 1 -

Accuracy:   0.916666666667  0.796296296296
Precision:  1.0             1.0
Recall:     0.888888888889  0.703703703704

Monk2 -

Accuracy:  0.530092592593   0.511574074074
Precision: 0.741228070175   0.757281553398
Recall:    0.58275862069    0.537931034483

Monk3 -

Accuracy:   0.91666666667   0.925925925926
Precision:  0.941176470588  0.96
Recall:     0.941176470588  0.941176470588

Iris-

Accuracy:   0.526315789474  0.710526315789
Precision:  0.75            1.0
Recall:     0.75            0.916666666667

*Naive Bayes*-

            Congress            Monk1           Monk2           Monk3           Iris
Accuracy:   .889908256881       .576388888889   .643259259259   .731481481481   .947368421053
Precision:  .971428571429       .551401869159   .674603174603   1.0             .909090909091
Recall:     .755555555556       .819444444444   .879310344828  .491228070175    .909090909091

*Neural Network* - 
Key: DW = default weight, AW = alternate weight, M = with momentum, NM = without momentum
            DW-NM           AW-NM           DW-M            AW-M
Congress-

Accuracy:
Precision:
Recall:

Monk1 -

Accuracy:
Precision:
Recall:

Monk2 -

Accuracy:
Precision:
Recall:

Monk3 -

Accuracy:
Precision:
Recall:

Iris-

Accuracy:
Precision:
Recall:

Discuss how the performances of the algorithms compare on each data set.

*Best Algorithms for each data set*
Congress:
Monk1:
Monk2:
Monk3:
Iris:

Which metrics do you use to determine this and how does the nature of the data set affect your decision?

Work Breakdown: 
Naive Bayes + Neural Networks : Adam
Decision Trees + Data: Sayge

Bugs: TODO
