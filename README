# ai_homework4
Implementation of ML algorithms for AI Homework4

Adam Poliak, Sayge Schell
Dec 4th, 2015

To run, do the following:
python train_and_test.py -d=congress -p=85 -m=0 -test
-d refers to the data set
-p refers to the percent, if -d is monk, then instead of -p=(int), do 1, 2, or 3 to determine with monk data set
-m refers to machine learning method

**TODO**
-igr refers to information gain ratio in the case m is the decision tree
-pr refers to pruning in the case m is the decision tree


Please note, for precision, the value for the first data set was chosen as the 'positive' one. All other values were set
to be negatives.

*Decision Trees* -
Key: IGR = Information Gain ratio, IG = Information Gain, NP = No pruning, P = Pruning

Congress- 
            IGR-NP          IG - NP             IGR -P              IGR - NP
Accuracy:   0.935889815614  0.926605504587
Precision:  0.403669724771  0.412844036697
Recall:     0.977777777778  1.0

Monk 1 -

Accuracy:   0.916666666667  0.796296296296
Precision:  0.472222222222  0.481481481481
Recall:     0.944444444444  0.962962962963

Monk2 -

Accuracy:  0.530092592593   0.513888888889
Precision: 0.527777777778   0.476851851852
Recall:    0.786205896552   0.710344827586

Monk3 -

Accuracy:   0.91666666667   0.925925925926
Precision:  0.47222222222   0.4818181818181
Recall:     0.894736842105  0.912280701754

Iris-

Accuracy:   0.526315789474  0.710526315789
Precision:  0.184210526315  0.289473684211
Recall:     0.636363636364  1.0

*Naive Bayes*-

            Congress            Monk1           Monk2           Monk3           Iris
Accuracy:   .889908256881       .576388888889   .643259259259   .731481481481   .947368421053
Precision:  .321100917431       .743055555556   .875            .259259259259   .289473684211
Recall:     .777777777778       1.48611111111   1.30344827586   1.30344827586   1.0

*Neural Network* - 
Key: DW = default weight, AW = alternate weight, M = with momentum, NM = without momentum
            DW-NM           AW-NM           DW-M            AW-M
Congress-

Accuracy:
Precision:
Recall:

Monk1 -

Accuracy:
Precision:
Recall:

Monk2 -

Accuracy:
Precision:
Recall:

Monk3 -

Accuracy:
Precision:
Recall:

Iris-

Accuracy:
Precision:
Recall:

Discuss how the performances of the algorithms compare on each data set.

*Best Algorithms for each data set*
Congress:
Monk1:
Monk2:
Monk3:
Iris:

Which metrics do you use to determine this and how does the nature of the data set affect your decision?

Work Breakdown: 
Naive Bayes + Neural Networks : Adam
Decision Trees + Data: Sayge

Bugs: TODO
